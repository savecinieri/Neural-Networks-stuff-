{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)   <class 'tuple'>\n",
      "(2, 3)\n",
      "(2, 3, 4)\n",
      "Number of axes:  3\n",
      "[35  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "## ---------- SEGNALIBRO ---------- ##\n",
    "# pag.56 (79), restart from chapter 3\n",
    "\n",
    "## ---------- THEORY ---------- ##\n",
    "# pag.46 to pag.52\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#before starting, tensors operations\n",
    "xVector = np.array([1, 22, 72]) # tensor of rank 1\n",
    "xMatrix = np.array([[1, 22, 72],\n",
    "                   [2, 44, 59]]) # tensor of rank 2\n",
    "xTensorRank3 = np.array([[[11, 2, 22, 1],\n",
    "                          [35, 1, 1, 1],\n",
    "                          [2, 11, 11, 1]\n",
    "                         ],\n",
    "                         [[11, 2, 2, 22],\n",
    "                          [3, 1, 1, 2],\n",
    "                          [2, 1, 11, 2]\n",
    "                         ]\n",
    "                        ])\n",
    "\n",
    "# \"shape\" attribute show dimensionality for each axes\n",
    "# \"ndim\" attribute is the rank( # of axes)\n",
    "print(xVector.shape, ' ', type(xVector.shape))\n",
    "print(xMatrix.shape)\n",
    "print(xTensorRank3.shape)\n",
    "\n",
    "print('Number of axes: ', xTensorRank3.ndim)\n",
    "print(xTensorRank3[0][1]) # with with a further index and differet combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 22]\n",
      " [72  2]\n",
      " [44 59]]  -> new dimensionality for each axes:  (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# \"reshape\" method modify diensionality\n",
    "xMatrix = xMatrix.reshape((3, 2))\n",
    "print(xMatrix, ' -> new dimensionality for each axes: ', xMatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of axis:  1  dimensionality for each axes: (25000,)\n",
      "# of axis:  1  dimensionality for each axes: (25000,)\n",
      "# of axis:  1  dimensionality for each axes: (25000,)\n",
      "<class 'numpy.ndarray'>  |||  <class 'numpy.ndarray'>\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32] // ----- // label:  1\n",
      "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95] // ----- // label:  0\n",
      "[1, 13, 104, 14, 9, 31, 7, 4, 4343, 7, 4, 3776, 3394, 2, 495, 103, 141, 87, 2048, 17, 76, 2, 44, 164, 525, 13, 197, 14, 16, 338, 4, 177, 16, 6118, 5253, 2, 2, 2, 21, 61, 1126, 2, 16, 15, 36, 4621, 19, 4, 2, 157, 5, 605, 46, 49, 7, 4, 297, 8, 276, 11, 4, 621, 837, 844, 10, 10, 25, 43, 92, 81, 2282, 5, 95, 947, 19, 4, 297, 806, 21, 15, 9, 43, 355, 13, 119, 49, 3636, 6951, 43, 40, 4, 375, 415, 21, 2, 92, 947, 19, 4, 2282, 1771, 14, 5, 106, 2, 1151, 48, 25, 181, 8, 67, 6, 530, 9089, 1253, 7, 4, 2] // ----- // label:  0\n",
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]]\n",
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# first neural network\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist, imdb \n",
    "\n",
    "#------------------- def methods -----------------------#\n",
    "\n",
    "# from [[1, 3, 44], [2, 313, 87, 100], [34, 22]] -> matrix [[0, 0, 1],\n",
    "#                                                          [1, 0, 0, 0], ... ]\n",
    "def transformData(data, dimHorizontalAxes):\n",
    "    result = np.zeros((len(data), dimHorizontalAxes))\n",
    "    \n",
    "    currentReview = 0\n",
    "    for review in data:\n",
    "        for word in review:\n",
    "            if result[currentReview, word] == 0:\n",
    "                # a word could be used multiple times in a single review\n",
    "                result[currentReview, word] = 1\n",
    "        currentReview += 1\n",
    "        \n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "print('# of axis: ', train_data.ndim, ' dimensionality for each axes:', train_data.shape)\n",
    "print('# of axis: ', train_labels.ndim, ' dimensionality for each axes:', train_labels.shape)\n",
    "\n",
    "print('# of axis: ', test_data.ndim, ' dimensionality for each axes:', test_data.shape)\n",
    "\n",
    "# each cell is a list of words(identified by an index), instead the label is a single value\n",
    "print(type(train_data), ' ||| ', type(train_labels))\n",
    "print(train_data[0],  '// ----- // label: ', train_labels[0])\n",
    "print(train_data[1],  '// ----- // label: ', train_labels[1])\n",
    "print(train_data[10000],  '// ----- // label: ', train_labels[10000])\n",
    "\n",
    "# Decode words\n",
    "'''\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "print(reverse_word_index)\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
    "print(decoded_review)\n",
    "'''\n",
    "\n",
    "# any kind of data must be transformed in a tensor with a number of rank\n",
    "# here we transform the starting train_data that is a 1Dtensor in a 2Dtensor\n",
    "# each value in a cell of any kind of tensor MUST BE A SINGLE VALUE\n",
    "\n",
    "dimensionalityHorizontalAxes = 10000 # we have almost 10000 words\n",
    "x_train = transformData(train_data[0:12499], dimensionalityHorizontalAxes)\n",
    "x_val = transformData(train_data[12499:24999], dimensionalityHorizontalAxes)\n",
    "x_test = transformData(test_data, dimensionalityHorizontalAxes)\n",
    "\n",
    "# convert labels in the right format\n",
    "y_train = np.asarray(train_labels[0:12499]).astype('float32')\n",
    "y_val = np.asarray(train_labels[12499:25000]).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "\n",
    "'''\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images.shape\n",
    "len(train_labels)\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' check method\\ncounter = 0\\nfor i in range(len(train_data_[0])):\\n    if train_data_[0, i] != train_data_[1, i]:\\n        counter += 1\\nprint(counter)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' check method\n",
    "counter = 0\n",
    "for i in range(len(train_data_[0])):\n",
    "    if train_data_[0, i] != train_data_[1, i]:\n",
    "        counter += 1\n",
    "print(counter)\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Saverio\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Saverio\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/4\n",
      " 1024/12499 [=>............................] - ETA: 18:42 - loss: 0.6906 - accuracy: 0.5488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saverio\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.132808). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499/12499 [==============================] - 647s 52ms/step - loss: 0.5578 - accuracy: 0.7885\n",
      "Epoch 2/4\n",
      "12499/12499 [==============================] - 3s 213us/step - loss: 0.3601 - accuracy: 0.8973\n",
      "Epoch 3/4\n",
      "12499/12499 [==============================] - 3s 213us/step - loss: 0.2634 - accuracy: 0.9202\n",
      "Epoch 4/4\n",
      "12499/12499 [==============================] - 3s 211us/step - loss: 0.2040 - accuracy: 0.9376\n",
      "25000/25000 [==============================] - 957s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "# model definition \n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,))) # 10000 features == words index\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy', # CHECK HOW FAR THE RESULT IS FROM THE BEST RESULT\n",
    "                                          # COMPUTED WITH TRAINING DATA\n",
    "              metrics=['accuracy'])  # CHECK ON THE BOOK\n",
    "\n",
    "\n",
    "model.fit(train_data, train_labels, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29574037357330324, 0.8816800117492676]\n"
     ]
    }
   ],
   "source": [
    "print(results) # loss score, accuracy\n",
    "#before 3.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
