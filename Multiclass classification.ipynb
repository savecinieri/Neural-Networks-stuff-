{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist, imdb, reuters\n",
    "\n",
    "\n",
    "#------------------- def methods -----------------------#\n",
    "\n",
    "# from [[1, 3, 44], [2, 313, 87, 100], [34, 22]] -> matrix [[0, 0, 1],\n",
    "#                                                          [1, 0, 0, 0], ... ]\n",
    "def transformData(data, dimHorizontalAxes):\n",
    "    result = np.zeros((len(data), dimHorizontalAxes))\n",
    "    \n",
    "    currentReview = 0\n",
    "    for review in data:\n",
    "        for word in review:\n",
    "            if result[currentReview, word] == 0:\n",
    "                # a word could be used multiple times in a single review\n",
    "                result[currentReview, word] = 1\n",
    "        currentReview += 1\n",
    "        \n",
    "    # print(result)\n",
    "    return result\n",
    "\n",
    "def transformLabels(data, dimHorizontalAxes):\n",
    "    result = np.zeros((len(data), dimHorizontalAxes))\n",
    "    \n",
    "    currentSample = 0\n",
    "    for lbl in data:\n",
    "        result[currentSample, lbl] = 1\n",
    "        currentSample += 1\n",
    " \n",
    "    # print(result)\n",
    "    return result\n",
    "\n",
    "def check_method(tmpTensor):\n",
    "    counter = 0\n",
    "    for i in range(len(tmpTensor[0])):\n",
    "        if tmpTensor[0, i] != tmpTensor[1, i]:\n",
    "            counter += 1\n",
    "\n",
    "    return counter\n",
    "#-------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types\n",
      "Train data and labels\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "Test data and labels\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "Rank and dimensionality for each axis\n",
      "- train data:\n",
      "1\n",
      "(8982,)\n",
      "- train labels:\n",
      "1\n",
      "(8982,)\n",
      "\n",
      "- test data\n",
      "1\n",
      "(2246,)\n",
      "- test labels:\n",
      "1\n",
      "(2246,)\n"
     ]
    }
   ],
   "source": [
    "# load data and analyze the type, rank and dimensionality for each rank \n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000) # at most 10000 words\n",
    "\n",
    "print('Data types')\n",
    "print('Train data and labels')\n",
    "print(type(train_data))\n",
    "print(type(train_labels))\n",
    "print('\\nTest data and labels')\n",
    "print(type(test_data))\n",
    "print(type(test_labels))\n",
    "\n",
    "print('\\nRank and dimensionality for each axis')\n",
    "print('- train data:')\n",
    "print(train_data.ndim)\n",
    "print(train_data.shape)\n",
    "\n",
    "print('- train labels:')\n",
    "print(train_labels.ndim)\n",
    "print(train_labels.shape)\n",
    "\n",
    "\n",
    "print('\\n- test data')\n",
    "print(test_data.ndim)\n",
    "print(test_data.shape)\n",
    "\n",
    "print('- test labels:')\n",
    "print(test_labels.ndim)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data content\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]  - label:  3\n",
      "\n",
      "Test data content\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]  - label:  3\n"
     ]
    }
   ],
   "source": [
    "print('Train data content')\n",
    "print(train_data[0], ' - label: ', train_labels[0])\n",
    "\n",
    "print('\\nTest data content')\n",
    "print(test_data[0], ' - label: ', test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to split train_data in x_train and x_val with their labels\n",
    "\n",
    "#AND\n",
    "\n",
    "# we must transform train_data in a tensor, \"1 value in each cell of the new data structure\" IS THE RULE\n",
    "# the new data structure for our problem is a tensor with rank 2\n",
    "# the features inside the matrix are the words, represented by a 0/1 for a word on the horizontal axes\n",
    "\n",
    "dimensionalityHorizontalAxes = 10000 # we have almost 10000 words\n",
    "x_train = transformData(train_data[:5982], dimensionalityHorizontalAxes)\n",
    "x_val = transformData(train_data[5982:len(train_data)], dimensionalityHorizontalAxes)\n",
    "\n",
    "x_test = transformData(test_data, dimensionalityHorizontalAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a multiclass classification problem the best format for the labels is a tensor of rank 2\n",
    "# for each sample on the vertical axes, and a vector on the horizontal axes with 0/1 for the class of that sample\n",
    "# the dimensionality for the horizontal axes is equalt to the number of class labels\n",
    "# 0 0 1 0 0 0 ... 0 0 0\n",
    "# 1 0 0 0 0 0 ... 0 0 0\n",
    "# 0 0 0 0 0 0 ... 1 0 0\n",
    "\n",
    "cardinalityClassLabels = 46\n",
    "y_train = transformLabels(train_labels[:5982], cardinalityClassLabels)\n",
    "y_val = transformLabels(train_labels[5982:len(train_labels)], cardinalityClassLabels)\n",
    "y_test = transformLabels(test_labels, cardinalityClassLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data types\n",
      "Train data and labels\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "Validation data and labels\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "Test data and labels\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "Rank and dimensionality for each axis\n",
      "- train data:\n",
      "2\n",
      "(5982, 10000)\n",
      "- train labels:\n",
      "2\n",
      "(5982, 46)\n",
      "- validation data:\n",
      "2\n",
      "(3000, 10000)\n",
      "- validation labels:\n",
      "2\n",
      "(3000, 46)\n",
      "\n",
      "- test data\n",
      "2\n",
      "(2246, 10000)\n",
      "- test labels:\n",
      "2\n",
      "(2246, 46)\n"
     ]
    }
   ],
   "source": [
    "print('New data types')\n",
    "print('Train data and labels')\n",
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print('\\nValidation data and labels')\n",
    "print(type(x_val))\n",
    "print(type(y_val))\n",
    "print('\\nTest data and labels')\n",
    "print(type(x_test))\n",
    "print(type(y_test))\n",
    "\n",
    "print('\\nRank and dimensionality for each axis')\n",
    "print('- train data:')\n",
    "print(x_train.ndim)\n",
    "print(x_train.shape)\n",
    "\n",
    "print('- train labels:')\n",
    "print(y_train.ndim)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "print('- validation data:')\n",
    "print(x_val.ndim)\n",
    "print(x_val.shape)\n",
    "\n",
    "print('- validation labels:')\n",
    "print(y_val.ndim)\n",
    "print(y_val.shape)\n",
    "\n",
    "\n",
    "\n",
    "print('\\n- test data')\n",
    "print(x_test.ndim)\n",
    "print(x_test.shape)\n",
    "\n",
    "print('- test labels:')\n",
    "print(y_test.ndim)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data content\n",
      "[0. 1. 1. ... 0. 0. 0.]  - label:  3\n",
      "\n",
      "Test data content\n",
      "[0. 1. 1. ... 0. 0. 0.]  - label:  3\n"
     ]
    }
   ],
   "source": [
    "print('\\nTrain data content')\n",
    "print(x_train[0], ' - label: ', train_labels[0])\n",
    "\n",
    "print('\\nTest data content')\n",
    "print(x_test[0], ' - label: ', test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "326\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "# check method\n",
    "print(check_method(x_train))\n",
    "print(check_method(x_test))\n",
    "print(check_method(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Saverio\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Saverio\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5982 samples, validate on 3000 samples\n",
      "Epoch 1/4\n",
      "5982/5982 [==============================] - 4s 749us/step - loss: 2.6911 - accuracy: 0.5000 - val_loss: 1.8369 - val_accuracy: 0.6553\n",
      "Epoch 2/4\n",
      "5982/5982 [==============================] - 2s 407us/step - loss: 1.5294 - accuracy: 0.6876 - val_loss: 1.4045 - val_accuracy: 0.7037\n",
      "Epoch 3/4\n",
      "5982/5982 [==============================] - 2s 409us/step - loss: 1.1353 - accuracy: 0.7589 - val_loss: 1.2212 - val_accuracy: 0.7407\n",
      "Epoch 4/4\n",
      "5982/5982 [==============================] - 2s 406us/step - loss: 0.9054 - accuracy: 0.8138 - val_loss: 1.1131 - val_accuracy: 0.7670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xd60177b6a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we an build our NN considering the problem we are going to face\n",
    "\n",
    "# model definition \n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,))) # 10000 features == words index\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "          \n",
    "          \n",
    "from keras import optimizers\n",
    "          \n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "# use verbose=0 if you don't want to see keras text\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 1s 382us/step\n",
      "[1.1791188423907448, 0.7528940439224243]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss score for train and validation data to understand where the overfitting happens\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
