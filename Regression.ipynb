{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "\n",
    "#------------------- def methods -----------------------#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and analyze the type, rank and dimensionality for each rank \n",
    "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n",
    "\n",
    "print('Data types')\n",
    "print('Train data and labels')\n",
    "print(type(train_data))\n",
    "print(type(train_labels))\n",
    "print('\\nTest data and labels')\n",
    "print(type(test_data))\n",
    "print(type(test_labels))\n",
    "\n",
    "print('\\nRank and dimensionality for each axis')\n",
    "print('- train data:')\n",
    "print(train_data.ndim)\n",
    "print(train_data.shape)\n",
    "\n",
    "print('- train labels:')\n",
    "print(train_labels.ndim)\n",
    "print(train_labels.shape)\n",
    "\n",
    "\n",
    "print('\\n- test data')\n",
    "print(test_data.ndim)\n",
    "print(test_data.shape)\n",
    "\n",
    "print('- test labels:')\n",
    "print(test_labels.ndim)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# having few data in training data involves that validation should be applied in a different way than done\n",
    "# in binary and multiclassification, for instance using k-fold validation. Moreover the neural network shouldn't be so complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train data content')\n",
    "print(train_data[0], ' - label: ', train_labels[0])\n",
    "\n",
    "print('\\nTest data content')\n",
    "print(test_data[0], ' - label: ', test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is in a good format (tensor) so we don't need to apply transformations\n",
    "# However we need to apply feature normalization because the values printed above are expressed on different numerical scales\n",
    "# train_data[0][2] << train_data[0][11]\n",
    "\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print again the data modified\n",
    "\n",
    "print('Train data content')\n",
    "print(train_data[0], ' - label: ', train_labels[0])\n",
    "\n",
    "print('\\nTest data content')\n",
    "print(test_data[0], ' - label: ', test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we an build our NN considering the problem we are going to face\n",
    "\n",
    "# model definition \n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(13,))) # 13 features, see the x dimensionality for the training_data tensor \n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "from keras import optimizers\n",
    "          \n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse', \n",
    "              metrics=['mae']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation should be applied using k-fold approach because the data we could include in validation couldn't be\n",
    "# generalize the data \n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitStatistics = model.fit(train_data, train_labels, epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(test_data, test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
